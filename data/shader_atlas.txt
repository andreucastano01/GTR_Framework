//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
skybox basic.vs skybox.fs
gamma basic.vs gamma.fs
gbuffers basic.vs gbuffers.fs
deferred quad.vs deferred.fs
sphere_deferred basic.vs deferred.fs
singlepass basic.vs singlepass.fs
multipass basic.vs multipass.fs
depth quad.vs depth.fs
ssao quad.vs ssao.fs
ssaoplus quad.vs ssaoplus.fs
ssao_blur quad.vs ssao_blur.fs
multi basic.vs multi.fs
tonemapper quad.vs tonemapper.fs
probe basic.vs probe.fs
decal basic.vs decal.fs
irradiance quad.vs irradiance.fs

\encodenormalmap

mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx(p);
	vec3 dp2 = dFdy(p);
	vec2 duv1 = dFdx(uv);
	vec2 duv2 = dFdy(uv);
	
	// solve the linear system
	vec3 dp2perp = cross(dp2, N);
	vec3 dp1perp = cross(N, dp1);
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt(max(dot(T,T), dot(B,B)));
	return mat3(T * invmax, B * invmax, N);
}

// assume N, the interpolated vertex normal and 
// WP the world position
//vec3 normal_pixel = texture2D(normalmap, uv).xyz; 
vec3 perturbNormal(vec3 N, vec3 WP, vec2 uv, vec3 normal_pixel)
{
	normal_pixel = normal_pixel * 255./127. - 128./127.;
	mat3 TBN = cotangent_frame(N, WP, uv);
	return normalize(TBN * normal_pixel);
}

\encodeshadowmap

uniform int u_light_cast_shadows;
uniform sampler2D u_light_shadowmap;
uniform mat4 u_light_shadowmap_vp;
uniform float u_light_shadow_bias;

float testShadowMap(vec3 pos){
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_light_shadowmap_vp * vec4(pos,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_light_shadow_bias) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;

	//read depth from depth buffer in [0..+1] non-linear
	float shadow_depth = texture(u_light_shadowmap, shadow_uv).x;

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;

	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		shadow_factor = 0.0;

	if(u_light_type == 0){
		//it is outside on the sides
		if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
			shadow_factor = 1.0;

		//it is before near or behind far plane
		if(real_depth < 0.0 || real_depth > 1.0)
			shadow_factor = 1.0;
	}

	return shadow_factor;
}

\specular_formulas

#define RECIPROCAL_PI 0.3183098861837697

float D_GGX (float NoH, float linearRoughness) {
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (3.1415926535 * f * f);
}

float F_Schlick1(float VoH, float f0, float f90) {
	float f = pow(1.0 - VoH, 5.0);
    return f0 + (f90 - f0) * f;
}

vec3 F_Schlick3(float VoH, vec3 f0) {
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

float GGX(float NdotV, float k) {
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith(float NdotV, float NdotL, float roughness) {
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

vec3 specularBRDF(float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH) {
	float a = roughness * roughness;

	// Normal Distribution Function
	float D = D_GGX(NoH, a);

	// Fresnel Function
	vec3 F = F_Schlick3(LoH, f0);

	// Visibility Function (shadowing/masking)
	float G = G_Smith(NoV, NoL, roughness);
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}

//Esto no funciona con el F_Shlick1 de las slides, sacado del enlace de la slide de FD_Burley
float Fd_Burley (float NoV, float NoL, float LoH, float linearRoughness) {
        float f90 = 0.5 + 2.0 * linearRoughness * LoH * LoH;
        float lightScatter = F_Schlick1(NoL, 1.0, f90);
        float viewScatter  = F_Schlick1(NoV, 1.0, f90);
        return lightScatter * viewScatter * RECIPROCAL_PI;
}

\linear

vec3 degamma(vec3 c)
{
	return pow(c,vec3(2.2));
}

vec3 gamma(vec3 c)
{
	return pow(c,vec3(1.0/2.2));
}

\SHformulas

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

uniform float u_time;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_coord;
out vec2 v_uv;

void main()
{	
	v_uv = a_coord;
	gl_Position = vec4(a_vertex, 1.0);
}


\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}


\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture(u_texture, v_uv);

	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}

\skybox.fs

#version 330 core

in vec3 v_world_position;

uniform samplerCube u_texture;
uniform vec3 u_camera_position;

out vec4 FragColor;

void main()
{
	vec3 V = normalize(v_world_position - u_camera_position);
	FragColor = texture(u_texture, V);
}

\gamma.fs

#version 330 core

in vec2 v_uv;
uniform sampler2D u_texture;

out vec4 FragColor;

void main()
{
	vec4 color = texture(u_texture,v_uv);
	color.xyz = pow(color.xyz,vec3(1.0/2.2));
	FragColor = color;
}


\gbuffers.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;
uniform int dither;

uniform vec3 u_emissive_factor;
uniform float u_roughness_factor;
uniform float u_metallic_factor;
uniform sampler2D u_texture_emissive;
uniform sampler2D u_texture_occlusion;
uniform int u_have_occlusion_texture;

uniform sampler2D u_texture_normal;
uniform int u_have_normal_texture;

layout(location = 0) out vec4 GB0;
layout(location = 1) out vec4 GB1;
layout(location = 2) out vec4 GB2;

#include "encodenormalmap"
#include "linear"

void main()
{
	vec3 N;
	if(u_have_normal_texture == 1){
		vec3 normal_pixel = texture2D(u_texture_normal, v_uv).xyz;
		N = normalize(perturbNormal(v_normal, v_world_position, v_uv, normal_pixel));
	}
	if(u_have_normal_texture == 0){
		N = normalize(v_normal);
	}
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture(u_texture, v_uv);

	if(color.a < u_alpha_cutoff)
		discard;

	vec4 material;
	if(u_have_occlusion_texture == 1) {
		material = texture(u_texture_occlusion, v_uv);
		material.y *= u_metallic_factor;
		material.z *= u_roughness_factor;
	}

	vec3 emissive_factor = u_emissive_factor;
	emissive_factor *= texture(u_texture_emissive, v_uv).xyz;

	vec3 linear_color = degamma(color.xyz);
	GB0 = vec4(color.xyz, material.x);
	GB1 = vec4(N * 0.5 + vec3(0.5), material.y);
	GB2 = vec4(emissive_factor, material.z);
}

\deferred.fs

#version 330 core

uniform vec2 u_iRes;

uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec3 u_light_color;
uniform float u_light_intensity;
uniform vec3 u_light_position;
uniform vec3 u_ambient_light;
uniform vec3 u_light_cone;
uniform vec3 u_light_front;
uniform vec3 u_light_vector;
uniform float u_light_max_distance;
uniform int u_light_type;
uniform vec3 u_camera_position;

uniform sampler2D u_ssao_texture;
uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_gb2_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;

out vec4 FragColor;

#include "encodeshadowmap"
#include "specular_formulas"
#include "linear"

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	vec4 gb0_color = texture(u_gb0_texture, uv);
	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec4 gb2_color = texture(u_gb2_texture, uv);
	vec4 color = vec4(degamma(gb0_color.xyz), 1.0);

	float depth = texture(u_depth_texture, uv).x;

	if(depth == 1.0) discard;

	vec4 screen_pos = vec4(uv.x * 2.0 - 1.0, uv.y * 2.0 - 1.0, depth * 2.0 - 1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));
	
	float ao_factor = texture(u_ssao_texture, uv).x;
	ao_factor = pow(ao_factor, 3.0);
	vec3 ambient = degamma(u_ambient_light);
	float occlusion = 1.0;
	if(gb0_color.a != 0.0) occlusion = gb0_color.a;
	occlusion = ao_factor;
	ambient *= occlusion;

	if(color.a < u_alpha_cutoff)
		discard;
	
	vec3 L;
	float spotFactor = 1.0;
	float ShadowFactor = 1.0;

	if(u_light_type == 1) { //spot light
		L = normalize(u_light_position - world_position);
		if (u_light_cone.z > 0){
			vec3 D = normalize(u_light_front);
			float spotCosine = dot(D, -L);
			if (spotCosine >= u_light_cone.z) {
				spotFactor = pow(spotCosine, u_light_cone.y);
			} 
			else spotFactor = 0.0; // The light will add no color to the point.
		}
		if(u_light_cast_shadows == 1) ShadowFactor = testShadowMap(world_position);
	}
	
	if(u_light_type == 2) { //point light
		L = normalize(u_light_position - world_position);
	}

	float light_distance = length(u_light_position - world_position);
	float att_factor = u_light_max_distance - light_distance;
	att_factor = att_factor/u_light_max_distance;
	att_factor = max(att_factor, 0.0);
	att_factor *= pow(att_factor, 2.0);

	if(u_light_type == 0) { //directional light
		L = normalize(u_light_vector);
		att_factor = 1.0;
		if(u_light_cast_shadows == 1) ShadowFactor = testShadowMap(world_position);
	}

	vec3 V = normalize(u_camera_position - world_position);
	vec3 H = normalize(L + V);

	float NdotH = clamp(dot(N, H), 0.0, 1.0);
	float NdotV = clamp(dot(N, V), 0.0, 1.0);
	float NdotL = clamp(dot(N, L), 0.0, 1.0);
	float LdotH = clamp(dot(L, H), 0.0, 1.0);

	vec3 fresnel = mix(vec3(0.5), color.xyz, gb1_color.a);
	vec3 diffuseColor = (1.0 - gb1_color.a) * color.xyz;

	vec3 Fr_d = specularBRDF(gb2_color.a, fresnel, NdotH, NdotV, NdotL, LdotH);

	// Here we use the Burley, but you can replace it by the Lambert.
	// linearRoughness = squared roughness
	vec3 Fd_d = diffuseColor * Fd_Burley(NdotV, NdotL, LdotH, pow(gb2_color.a, 2.0));

	vec3 direct = Fr_d + Fd_d;

	vec3 lightParams = degamma(u_light_color) * u_light_intensity * att_factor * spotFactor * ShadowFactor;

	vec3 light = direct * lightParams + ambient;
	color.xyz *= light;
	color.xyz += degamma(gb2_color.xyz);
	
	FragColor = color;
}

\singlepass.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec3 u_emissive_factor;
uniform sampler2D u_texture_emissive;
uniform sampler2D u_texture_normal;
uniform sampler2D u_texture_occlusion;
uniform vec3 u_ambient_light;
uniform int u_have_normal_texture;
uniform int u_have_occlusion_texture;

const int MAX_LIGHTS = 5;
uniform vec3 u_light_position[MAX_LIGHTS];
uniform vec3 u_light_color[MAX_LIGHTS];
uniform int u_light_type[MAX_LIGHTS];
uniform float u_light_max_distance[MAX_LIGHTS];
uniform vec3 u_light_cone[MAX_LIGHTS];
uniform vec3 u_light_vector[MAX_LIGHTS];
uniform vec3 u_light_front[MAX_LIGHTS];
uniform int u_num_lights;

uniform int u_light_cast_shadows[MAX_LIGHTS];
uniform sampler2D u_light_shadowmap[MAX_LIGHTS];
uniform float u_light_shadow_bias[MAX_LIGHTS];
uniform mat4 u_light_shadowmap_vp[MAX_LIGHTS];

out vec4 FragColor;

#include "encodenormalmap"

float testShadowMap(vec3 pos, int i){
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_light_shadowmap_vp[i] * vec4(pos,1.0);

	//from homogeneus space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;

	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth [-1 .. +1] in non-linear space
	float real_depth = (proj_pos.z - u_light_shadow_bias[i]) / proj_pos.w;

	//normalize from [-1..+1] to [0..+1] still non-linear
	real_depth = real_depth * 0.5 + 0.5;

	//read depth from depth buffer in [0..+1] non-linear
	float shadow_depth = texture(u_light_shadowmap[i], shadow_uv).x;

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;

	//we can compare them, even if they are not linear
	if( shadow_depth < real_depth )
		shadow_factor = 0.0;

	if(u_light_type[i] == 0){ //Falta arreglar la directional para las sombras
		//it is outside on the sides
		if( shadow_uv.x < 0.0 || shadow_uv.x > 1.0 || shadow_uv.y < 0.0 || shadow_uv.y > 1.0 )
			shadow_factor = 1.0;

		//it is before near or behind far plane
		if(real_depth < 0.0 || real_depth > 1.0)
			shadow_factor = 1.0;
	}

	return shadow_factor;
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, v_uv );

	vec3 emissive_factor = u_emissive_factor;
	emissive_factor *= texture(u_texture_emissive, v_uv).xyz;

	vec3 N;
	if(u_have_normal_texture == 1){
		vec3 normal_pixel = texture2D(u_texture_normal, v_uv).xyz;
		N = normalize(perturbNormal(v_normal, v_world_position, v_uv, normal_pixel));
	}
	if(u_have_normal_texture == 0){
		N = normalize(v_normal);
	}

	vec3 ambient = u_ambient_light;
	if(u_have_occlusion_texture == 1){
		ambient *= texture(u_texture_occlusion, v_uv).x;
	}

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 light = ambient;
	
	for(int i = 0; i < MAX_LIGHTS; i++) {
		if(i < u_num_lights){
			vec3 L;
			float spotFactor = 1.0;
			float ShadowFactor = 1.0;

			if(u_light_type[i] == 1) { //spot light
				L = normalize(u_light_position[i] - v_world_position);
				if (u_light_cone[i].z > 0){
					vec3 D = normalize(u_light_front[i]);
					float spotCosine = dot(D, -L);
					if (spotCosine >= u_light_cone[i].z) {
						spotFactor = pow(spotCosine, u_light_cone[i].y);
					} 
					else spotFactor = 0.0; // The light will add no color to the point.
				}
				if(u_light_cast_shadows[i] == 1) ShadowFactor = testShadowMap(v_world_position, i);
			}
	
			if(u_light_type[i] == 2) { //point light
				L = normalize(u_light_position[i] - v_world_position);
			}

			float light_distance = length(u_light_position[i] - v_world_position);
			float att_factor = u_light_max_distance[i] - light_distance;
			att_factor = att_factor/u_light_max_distance[i];
			att_factor = max(att_factor, 0.0);
			att_factor *= pow(att_factor, 2.0);

			if(u_light_type[i] == 0) { //directional light
				L = normalize(u_light_vector[i]);
				att_factor = 1.0;
				//if(u_light_cast_shadows[i] == 1) ShadowFactor = testShadowMap(v_world_position, i);
			}

			float NdotL = clamp(dot(N, L), 0.0, 1.0);
			light += NdotL * u_light_color[i] * att_factor * spotFactor * ShadowFactor;
		}
	}

	color.xyz *= light;
	color.xyz += emissive_factor;

	FragColor = color;
}

\multipass.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec3 u_light_color;
uniform float u_light_intensity;
uniform vec3 u_light_position;
uniform vec3 u_ambient_light;
uniform vec3 u_light_cone;
uniform vec3 u_light_front;
uniform vec3 u_light_vector;
uniform float u_light_max_distance;
uniform int u_light_type;
uniform vec3 u_camera_position;

uniform vec3 u_emissive_factor;
uniform sampler2D u_texture_emissive;
uniform sampler2D u_texture_normal;
uniform sampler2D u_texture_occlusion;
uniform int u_have_normal_texture;
uniform int u_have_occlusion_texture;
uniform float u_roughness_factor;
uniform float u_metallic_factor;

#include "encodenormalmap"
#include "encodeshadowmap"
#include "specular_formulas"

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture(u_texture, v_uv);

	vec3 emissive_factor = u_emissive_factor;
	emissive_factor *= texture(u_texture_emissive, v_uv).xyz;

	vec3 N;
	if(u_have_normal_texture == 1){
		vec3 normal_pixel = texture2D(u_texture_normal, v_uv).xyz;
		N = normalize(perturbNormal(v_normal, v_world_position, v_uv, normal_pixel));
	}
	if(u_have_normal_texture == 0){
		N = normalize(v_normal);
	}
	
	vec3 ambient = u_ambient_light;
	float metalness;
	float roughness;
	if(u_have_occlusion_texture == 1){
		ambient *= texture(u_texture_occlusion, v_uv).x;
		metalness = texture(u_texture_occlusion, v_uv).y;
		metalness *= u_metallic_factor;
		roughness = texture(u_texture_occlusion, v_uv).z;
		roughness *= u_roughness_factor;
	}

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 light = ambient;
	
	vec3 L;
	float spotFactor = 1.0;
	float ShadowFactor = 1.0;

	if(u_light_type == 1) { //spot light
		L = normalize(u_light_position - v_world_position);
		if (u_light_cone.z > 0){
			vec3 D = normalize(u_light_front);
			float spotCosine = dot(D, -L);
			if (spotCosine >= u_light_cone.z) {
				spotFactor = pow(spotCosine, u_light_cone.y);
			} 
			else spotFactor = 0.0; // The light will add no color to the point.
		}
		if(u_light_cast_shadows == 1) ShadowFactor = testShadowMap(v_world_position);
	}
	
	if(u_light_type == 2) { //point light
		L = normalize(u_light_position - v_world_position);
	}

	float light_distance = length(u_light_position - v_world_position);
	float att_factor = u_light_max_distance - light_distance;
	att_factor = att_factor/u_light_max_distance;
	att_factor = max(att_factor, 0.0);
	att_factor *= pow(att_factor, 2.0);

	if(u_light_type == 0) { //directional  light
		L = normalize(u_light_vector);
		att_factor = 1.0;
		if(u_light_cast_shadows == 1) ShadowFactor = testShadowMap(v_world_position);
	}

	vec3 V = normalize(u_camera_position - v_world_position);
	vec3 H = normalize(L + V);

	float NdotH = clamp(dot(N, H), 0.0, 1.0);
	float NdotV = clamp(dot(N, V), 0.0, 1.0);
	float NdotL = clamp(dot(N, L), 0.0, 1.0);
	float LdotH = clamp(dot(L, H), 0.0, 1.0);

	vec3 fresnel = mix(vec3(0.5), color.xyz, metalness);
	vec3 diffuseColor = (1.0 - metalness) * color.xyz;

	vec3 Fr_d = specularBRDF(roughness, fresnel, NdotH, NdotV, NdotL, LdotH);

	// Here we use the Burley, but you can replace it by the Lambert.
	// linearRoughness = squared roughness
	vec3 Fd_d = diffuseColor * Fd_Burley(NdotV, NdotL, LdotH, pow(roughness, 2.0)); 

	vec3 direct = Fr_d + Fd_d;

	vec3 lightParams = u_light_color * u_light_intensity * att_factor * spotFactor * ShadowFactor;

	light += direct * lightParams;

	color.xyz *= light;
	color.xyz += emissive_factor;

	FragColor = color;
}


\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	FragColor = color;
	NormalColor = vec4(N,1.0);
}


\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}

\ssao.fs

#version 330 core

uniform vec2 u_iRes;

uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec3 u_points[128];

out vec4 FragColor;

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	
	float depth = texture(u_depth_texture, uv).x;
	if(depth >= 1.0){
		FragColor = vec4(1.0);
		return;
	}

	vec4 screen_pos = vec4(uv.x * 2.0 - 1.0, uv.y * 2.0 - 1.0, depth * 2.0 - 1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	//lets use 128 samples
	const int samples = 128;
	int num = samples; //num samples that passed the are outside

	//for every sample around the point
	for(int i = 0; i < samples; i++)
	{
		//compute is world position using the random
		vec3 p = world_position + u_points[i] * 2.0;
		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(p,1.0);
		proj.xy /= proj.w; //convert to clipspace from homogeneous
		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - 0.005) / proj.w;
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]
		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;
		//compare true depth with its depth
		if(pdepth < proj.z) //if true depth smaller, is inside
			num--; //remove this point from the list of visible
	}

	//finally, compute the AO factor as the ratio of visible points
	float ao = float(num) / float(samples);

	FragColor = vec4(ao);
}

\ssaoplus.fs

#version 330 core

uniform vec2 u_iRes;

uniform sampler2D u_depth_texture;
uniform sampler2D u_gb1_texture;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec3 u_points[128];

out vec4 FragColor;

#include "encodenormalmap"

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	
	float depth = texture(u_depth_texture, uv).x;
	if(depth >= 1.0){
		FragColor = vec4(1.0);
		return;
	}

	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));

	vec4 screen_pos = vec4(uv.x * 2.0 - 1.0, uv.y * 2.0 - 1.0, depth * 2.0 - 1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	//lets use 128 samples
	const int samples = 128;
	int num = samples; //num samples that passed the are outside

	mat3 rotmat = cotangent_frame(gb1_color.xyz, world_position, uv);

	//for every sample around the point
	for(int i = 0; i < samples; i++)
	{
		//rotate a point is easy
		vec3 rotated_point = rotmat * u_points[i];

		//compute is world position using the random
		vec3 p = world_position + rotated_point * 2.0;
		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(p, 1.0);
		proj.xy /= proj.w; //convert to clipspace from homogeneous
		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - 0.005) / proj.w;
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]
		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;
		//compare true depth with its depth
		if(pdepth < proj.z) //if true depth smaller, is inside
			num--; //remove this point from the list of visible
	}

	//finally, compute the AO factor as the ratio of visible points
	float ao = float(num) / float(samples);

	FragColor = vec4(ao);
}

//Blur in slide 49 from http://vis.uni-jena.de/Lecture/ComputerGraphics2/Lec12_b_SSAO.pdf
\ssao_blur.fs

#version 330 core

in vec2 v_uv;
uniform sampler2D ssaoInput;

out float FragColor;

void main() {
	vec2 texelSize = 1.0 / vec2(textureSize(ssaoInput, 0));
	float result = 0.0;
	for (int x = -2; x < 2; ++x) {
		for (int y = -2; y < 2; ++y) {
			vec2 offset = vec2(float(x), float(y)) * texelSize;
			result += texture(ssaoInput, v_uv + offset).r;
		}
	}
	FragColor = result / (4.0 * 4.0);
} 

\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_coord;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_coord;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\tonemapper.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform float u_average_lum; //1.0 por ejemplo
uniform float u_lumwhite2; //intluz * intluz
uniform float u_scale; //1.0 por ejemplo 

out vec4 FragColor;

#include "linear"

void main() {
	vec4 color = texture2D(u_texture, v_uv);
	vec3 rgb = color.xyz;

	float lum = dot(rgb, vec3(0.2126, 0.7152, 0.0722));
	float L = (u_scale / u_average_lum) * lum;
	float Ld = (L * (1.0 + L / u_lumwhite2)) / (1.0 + L);

	rgb = (rgb / lum) * Ld;
	rgb = max(rgb,vec3(0.001));
	rgb = gamma(rgb);
	FragColor = vec4(rgb, color.a);
}

\probe.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec3 u_coeffs[9];

out vec4 FragColor;

#include "SHformulas"

void main()
{
	SH9Color sh;
	sh.c[0] = u_coeffs[0];
	sh.c[1] = u_coeffs[1];
	sh.c[2] = u_coeffs[2];
	sh.c[3] = u_coeffs[3];
	sh.c[4] = u_coeffs[4];
	sh.c[5] = u_coeffs[5];
	sh.c[6] = u_coeffs[6];
	sh.c[7] = u_coeffs[7];
	sh.c[8] = u_coeffs[8];

	vec3 N = normalize(v_normal);
	//now we can use the coefficients to compute the irradiance
	vec3 irradiance = ComputeSHIrradiance(N, sh);

	FragColor = vec4(irradiance, 1.0);
}

\decal.fs

#version 330 core

uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_pos;
uniform mat4 u_imodel;

uniform sampler2D u_depth_texture;
uniform sampler2D u_decal_texture;

out vec4 FragColor;

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	
	float depth = texture(u_depth_texture, uv).x;

	vec4 screen_pos = vec4(uv.x * 2.0 - 1.0, uv.y * 2.0 - 1.0, depth * 2.0 - 1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	vec3 localpos = (u_imodel * vec4(world_position,1.0)).xyz;

	//if outside of the volume
	//if( localpos.x < -0.5 || localpos.x > 0.5 || localpos.y < -0.5 || localpos.y > 0.5 || localpos.z < -0.5 || localpos.z > 0.5 )
	//	discard;

	vec2 decal_uv = localpos.xz + vec2(0.5);
	vec4 color = texture(u_decal_texture, uv);
	//vec4 color = vec4(world_position.xyz*0.01, 1.0);

	FragColor = color;
}

\irradiance.fs

#version 330 core

uniform vec2 u_iRes;

uniform sampler2D u_depth_texture;
uniform sampler2D u_gb0_texture;
uniform sampler2D u_gb1_texture;
uniform sampler2D u_irr_texture;

uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec3 u_irr_start;
uniform vec3 u_irr_end;
uniform vec3 u_irr_dim;
uniform float u_irr_normal_distance;
uniform float u_num_probes;
uniform vec3 u_irr_delta;

out vec4 FragColor;

#include "SHformulas"

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	
	float depth = texture(u_depth_texture, uv).x;
	if(depth >= 1.0){
		FragColor = vec4(1.0);
		return;
	}

	vec4 gb1_color = texture(u_gb1_texture, uv);
	vec3 N = normalize(gb1_color.xyz * 2.0 - vec3(1.0));

	vec4 screen_pos = vec4(uv.x * 2.0 - 1.0, uv.y * 2.0 - 1.0, depth * 2.0 - 1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 world_position = proj_worldpos.xyz / proj_worldpos.w;

	//computing nearest probe index based on world position
	vec3 irr_range = u_irr_end - u_irr_start;
	vec3 irr_local_pos = clamp(world_position - u_irr_start + N * u_irr_normal_distance, vec3(0.0), irr_range);

	//convert from world pos to grid pos
	vec3 irr_norm_pos = irr_local_pos / u_irr_delta;

	//round values as we cannot fetch between rows for now
	vec3 local_indices = round(irr_norm_pos);

	//compute in which row is the probe stored
	float row = local_indices.x + local_indices.y * u_irr_dim.x + local_indices.z * u_irr_dim.x * u_irr_dim.y;

	//find the UV.y coord of that row in the probes texture
	float row_uv = (row + 1.0) / (u_num_probes + 1.0);

	SH9Color sh;

	//fill the coefficients
	const float d_uvx = 1.0 / 9.0;
	for(int i = 0; i < 9; i++) {
		vec2 coeffs_uv = vec2((float(i)+0.5) * d_uvx, row_uv);
		sh.c[i] = texture(u_irr_texture, coeffs_uv).xyz;
	}

	//now we can use the coefficients to compute the irradiance
	vec3 irradiance = ComputeSHIrradiance(N, sh);

	vec3 color = texture(u_gb0_texture, uv).xyz * irradiance;

	FragColor = vec4(color, 1.0);
}